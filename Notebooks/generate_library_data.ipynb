{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d8ca4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.SettingWithCopyWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c12fec",
   "metadata": {},
   "source": [
    "*Define tables*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0dab9742",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = pd.DataFrame(columns=[\"description_id\", \"description\"])\n",
    "author = pd.DataFrame(columns=[\"author_id\", \"name\"])\n",
    "category = pd.DataFrame(columns=[\"category_id\", \"category_name\"])\n",
    "book = pd.DataFrame(columns=[\"ISBN\", \"title\", \"publication_year\", \"description_id\"])\n",
    "book_author = pd.DataFrame(columns=[\"ISBN\", \"author_id\"])\n",
    "book_category = pd.DataFrame(columns=[\"ISBN\", \"category_id\"])\n",
    "book_copy = pd.DataFrame(columns=[\"copy_id\", \"status\", \"condition\", \"price\", \"ISBN\"])\n",
    "member = pd.DataFrame(columns=[\"member_id\", \"fname\", \"lname\", \"email\", \"phone\", \"city\", \"street\", \"bdate\"])\n",
    "staff = pd.DataFrame(columns=[\"staff_id\", \"fname\", \"lname\", \"email\", \"phone\", \"role\", \"password\", \"salary\"])\n",
    "reservation = pd.DataFrame(columns=[\"reservation_id\", \"member_id\", \"staff_id\", \"reservation_date\", \"expiration_date\", \"returned_at\"])\n",
    "reservation_details = pd.DataFrame(columns=[\"reservation_id\", \"copy_id\", \"position_in_queue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bebd3ec",
   "metadata": {},
   "source": [
    "*Read books1 data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "35dffb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mekod\\AppData\\Local\\Temp\\ipykernel_4108\\2799744457.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books_data1 = pd.read_csv(\n"
     ]
    }
   ],
   "source": [
    "books_data1 = pd.read_csv(\n",
    "    \"C:/Users/mekod/Desktop/Database_project/Data/Kaggle datasets/books1.csv\",\n",
    "    sep=\";\",\n",
    "    quotechar='\"',\n",
    "    encoding=\"cp1252\",\n",
    "    on_bad_lines=\"skip\"\n",
    ")\n",
    "books_data1 = books_data1.loc[books_data1['ISBN'].notna()]\n",
    "books_data1 = books_data1.iloc[:2500, :3]\n",
    "books_data1 = books_data1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc33f02",
   "metadata": {},
   "source": [
    "*Read books2 data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ebfb5ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "books_data2 = pd.read_csv(\n",
    "    \"C:/Users/mekod/Desktop/Database_project/Data/Kaggle datasets/books2.csv\",\n",
    "    sep=\",\",      \n",
    "    quotechar='\"',      \n",
    "    encoding=\"utf-8\",  \n",
    "    on_bad_lines=\"skip\" \n",
    ")\n",
    "books_data2 = books_data2.loc[books_data2['Description'].notna()]\n",
    "books_data2.drop_duplicates(inplace=True)\n",
    "books_data2 = books_data2.reset_index(drop=True)\n",
    "books_data2 = books_data2.iloc[:2500]\n",
    "books_data2 = books_data2.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "89bbf16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data2['ISBN'] = books_data1['ISBN']\n",
    "books_data2['description_id'] = range(1, len(books_data2) + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613ee922",
   "metadata": {},
   "source": [
    "# description table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "38578b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "description = books_data2[[\"description_id\", \"Description\"]]\n",
    "book = books_data2[[\"ISBN\", \"Title\", \"Publish Date (Year)\", \"description_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0d7a1b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_data2['Authors'] = books_data2['Authors'].str.replace(r'^By\\s+', '', regex=True)\n",
    "books_data2['Authors_list'] = books_data2['Authors'].str.split(\",\")\n",
    "books_data2['Category_list'] = books_data2['Category'].str.split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "77441f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "books_expanded = (\n",
    "    books_data2\n",
    "    .explode(\"Authors_list\")    \n",
    "    .explode(\"Category_list\")   \n",
    ")\n",
    "\n",
    "books_expanded['Authors_list'] = books_expanded['Authors_list'].str.strip()\n",
    "books_expanded['Category_list'] = books_expanded['Category_list'].str.strip()\n",
    "\n",
    "books_data2[\"Authors_list\"] = books_data2[\"Authors_list\"].str.strip()\n",
    "books_data2[\"Category_list\"] = books_data2[\"Category_list\"].str.strip()\n",
    "\n",
    "book_author = books_expanded[[\"ISBN\", \"Authors_list\"]].dropna().drop_duplicates().reset_index(drop=True)\n",
    "book_category = books_expanded[[\"ISBN\", \"Category_list\"]].dropna().drop_duplicates(subset=['ISBN', 'Category_list']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e64b33",
   "metadata": {},
   "source": [
    "# Author table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "542baadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "author = pd.DataFrame(book_author['Authors_list'].drop_duplicates().reset_index(drop=True), columns=['Authors_list'])\n",
    "author['author_id'] = author.index + 1\n",
    "\n",
    "book_author = book_author.merge(\n",
    "    author,\n",
    "    on='Authors_list',\n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353dd812",
   "metadata": {},
   "source": [
    "# Category table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1dca9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "category = pd.DataFrame(\n",
    "    book_category['Category_list']\n",
    "    .drop_duplicates()\n",
    "    .reset_index(drop=True),\n",
    "    columns=['Category_list']\n",
    ")\n",
    "\n",
    "category['category_id'] = category.index + 1\n",
    "\n",
    "\n",
    "book_category = book_category.merge(\n",
    "    category,\n",
    "    left_on='Category_list',\n",
    "    right_on='Category_list', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "book_category = book_category[['ISBN', 'category_id']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e2a82f",
   "metadata": {},
   "source": [
    "**Rename columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5bc14fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "description.rename(columns={\"Description\": \"description\"}, inplace=True)\n",
    "book.rename(columns={\"Title\": \"title\", \"Publish Date (Year)\" : \"publication_year\" }, inplace= True)\n",
    "author.rename(columns={\"Authors_list\": \"name\"}, inplace= True)\n",
    "category.rename(columns={\"Category_list\": \"category_name\"}, inplace= True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f621eb0f",
   "metadata": {},
   "source": [
    "# Member Table\n",
    "\n",
    "This code generates **3,000 library members** with randomized details:\n",
    "\n",
    "- **Fields Generated**:\n",
    "  - `member_id`: Unique identifier\n",
    "  - `fname` / `lname`: Random first and last names\n",
    "  - `email`: Unique email\n",
    "  - `phone`: Unique phone number\n",
    "  - `city` / `street`: Random Egyptian city and street\n",
    "  - `bdate`: Random date of birth (ages 18–80)\n",
    "\n",
    "**Output**:\n",
    "\n",
    "- `member`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "95b4b449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faker import Faker\n",
    "\n",
    "fake = Faker('ar_EG')\n",
    "\n",
    "emails = set()\n",
    "phones = set()\n",
    "\n",
    "member = []\n",
    "for i in range(3000):\n",
    "    email = fake.unique.email()\n",
    "    phone = fake.unique.phone_number()\n",
    "    member.append({\n",
    "        \"member_id\": i + 1,\n",
    "        \"fname\": fake.first_name(),\n",
    "        \"lname\": fake.last_name(),\n",
    "        \"email\": email,\n",
    "        \"phone\": phone,\n",
    "        \"city\": fake.city(),\n",
    "        \"street\": fake.street_address(),\n",
    "        \"bdate\": fake.date_of_birth(minimum_age=18, maximum_age=80)\n",
    "    })\n",
    "    \n",
    "member = pd.DataFrame(member)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ae6748",
   "metadata": {},
   "source": [
    "# Staff Table\n",
    "\n",
    "This code generates **100 staff members** with randomized details:\n",
    "\n",
    "- **Manager Assignment**: First 3 staff are assigned the role `Manager`.\n",
    "- **Other Roles**: Remaining staff randomly assigned `Librarian`, `Assistant`, or `Technician`.\n",
    "- **Fields Generated**:\n",
    "  - `staff_id`: Unique identifier\n",
    "  - `fname` / `lname`: Random first and last names\n",
    "  - `email`: Unique email\n",
    "  - `phone`: Unique phone number\n",
    "  - `role`: Staff role (Manager or other roles)\n",
    "  - `password`: Random 8-character alphanumeric string\n",
    "  - `salary`: Random float between 5000 and 15000\n",
    "\n",
    "**Output**:\n",
    "\n",
    "- `staff` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c0ea11f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "\n",
    "fake = Faker('ar_EG')\n",
    "\n",
    "other_roles = [ 'Librarian', 'Assistant', 'Technician']\n",
    "\n",
    "staff = []\n",
    "\n",
    "for i in range(100):\n",
    "    email = fake.unique.email()\n",
    "    phone = fake.unique.phone_number()\n",
    "    password = ''.join(random.choices(string.ascii_letters + string.digits, k=8))\n",
    "    salary = round(random.uniform(5000, 15000), 2)\n",
    "    if i < 3:\n",
    "        role = 'Manager'\n",
    "    else:\n",
    "        role = random.choice(other_roles)\n",
    "    \n",
    "    staff.append({\n",
    "        \"staff_id\": i + 1,\n",
    "        \"fname\": fake.first_name(),\n",
    "        \"lname\": fake.last_name(),\n",
    "        \"email\": email,\n",
    "        \"phone\": phone,\n",
    "        \"role\": role,\n",
    "        \"password\": password,\n",
    "        \"salary\": salary\n",
    "    })\n",
    "\n",
    "staff = pd.DataFrame(staff)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394e7b5b",
   "metadata": {},
   "source": [
    "# Book_Copy Table\n",
    "\n",
    "## Generate Book Copies\n",
    "\n",
    "This code creates 5,000 book copies with randomized attributes:\n",
    "\n",
    "- **ISBN**: Randomly selected from the `book` table.\n",
    "- **Status**: One of `Available`, `Reserved`, or `Checked Out`.\n",
    "- **Condition**: One of `New`, `Good`, `Fair`, or `Poor`.\n",
    "- **Price**: Random value between 20 and 150.\n",
    "- **copy_id**: Unique identifier for each copy.\n",
    "\n",
    "**Output**:\n",
    "\n",
    "- `book_copy` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1913333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "isbn_list = book['ISBN'].tolist()  \n",
    "statuses = ['Available', 'Reserved', 'Checked Out']\n",
    "conditions = ['New', 'Good', 'Fair', 'Poor']\n",
    "\n",
    "book_copies = []\n",
    "\n",
    "num_copies = 5000 \n",
    "\n",
    "for i in range(num_copies):\n",
    "    isbn = random.choice(isbn_list) \n",
    "    status = random.choice(statuses)\n",
    "    condition = random.choice(conditions)\n",
    "    price = round(random.uniform(20, 150), 2)\n",
    "    \n",
    "    book_copies.append({\n",
    "        \"copy_id\": i + 1,\n",
    "        \"status\": status,\n",
    "        \"condition\": condition,\n",
    "        \"price\": price,\n",
    "        \"ISBN\": isbn\n",
    "    })\n",
    "\n",
    "book_copy = pd.DataFrame(book_copies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db631737",
   "metadata": {},
   "source": [
    "# Reservation Table\n",
    "\n",
    "This script generates reservations and reservation details for library members:\n",
    "\n",
    "- Each member makes 1–2 reservations, handled only by Assistants.\n",
    "- Each reservation has a start date, expiration date, and returned_at (80% chance returned).\n",
    "- Each reservation gets 1–3 book copies, with a max queue of 5 per copy.\n",
    "- Returned books free up copies for new reservations.\n",
    "- `book_copy` status is updated dynamically: Checked Out if not returned, Available otherwise.\n",
    "\n",
    "**Output:**\n",
    "\n",
    "- `df_reservation` → reservation info\n",
    "- `df_reservation_details` → copy assignments and queue positions\n",
    "- `df_book_copy_updated` → updated copy status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "38da31bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Convert member and staff lists to DataFrames for easier handling\n",
    "df_member = pd.DataFrame(member)\n",
    "df_staff = pd.DataFrame(staff)\n",
    "df_book_copy_updated = pd.DataFrame(book_copy)  # Assuming book_copy is already a list of dicts\n",
    "\n",
    "reservation_list = []\n",
    "reservation_details_list = []\n",
    "\n",
    "# Track queue per copy\n",
    "copy_queues = {copy_id: [] for copy_id in df_book_copy_updated['copy_id']}\n",
    "\n",
    "reservation_id_counter = 1\n",
    "\n",
    "for _, member_row in df_member.iterrows():\n",
    "    # Each member makes 1-2 reservations randomly\n",
    "    num_reservations = random.randint(1, 2)\n",
    "    \n",
    "    for _ in range(num_reservations):\n",
    "        # Pick a random Assistant for the reservation\n",
    "        assistants = df_staff[df_staff['role'] == 'Assistant']\n",
    "        staff_id = random.choice(assistants['staff_id'].tolist())\n",
    "        \n",
    "        # Generate reservation date\n",
    "        reservation_date = datetime(2025, 1, 1) + timedelta(days=random.randint(0, 365*2))\n",
    "        expiration_date = reservation_date + timedelta(days=random.randint(7, 21))  # 1-3 weeks loan\n",
    "        \n",
    "        # Determine returned_at (80% chance returned)\n",
    "        if random.random() <= 0.8:\n",
    "            returned_at = reservation_date + timedelta(days=random.randint(1, (expiration_date - reservation_date).days))\n",
    "        else:\n",
    "            returned_at = None\n",
    "        \n",
    "        # Add reservation\n",
    "        reservation_list.append({\n",
    "            \"reservation_id\": reservation_id_counter,\n",
    "            \"member_id\": member_row['member_id'],\n",
    "            \"staff_id\": staff_id,\n",
    "            \"reservation_date\": reservation_date,\n",
    "            \"expiration_date\": expiration_date,\n",
    "            \"returned_at\": returned_at\n",
    "        })\n",
    "        \n",
    "        # Assign 1-3 book copies for this reservation\n",
    "        num_copies = random.randint(1, 3)\n",
    "        available_copies = df_book_copy_updated['copy_id'].tolist()\n",
    "        random.shuffle(available_copies)\n",
    "        \n",
    "        assigned = 0\n",
    "        for copy_id in available_copies:\n",
    "            queue = copy_queues[copy_id]\n",
    "            \n",
    "            # Limit queue length to 5\n",
    "            if len(queue) < 5:\n",
    "                # Check availability: available if last in queue returned or no queue\n",
    "                last_returned = queue[-1]['returned_at'] if queue else returned_at\n",
    "                if not queue or last_returned is not None:\n",
    "                    position_in_queue = len(queue) + 1\n",
    "                    queue.append({\"reservation_id\": reservation_id_counter, \"returned_at\": returned_at})\n",
    "                    \n",
    "                    reservation_details_list.append({\n",
    "                        \"reservation_id\": reservation_id_counter,\n",
    "                        \"copy_id\": copy_id,\n",
    "                        \"position_in_queue\": position_in_queue\n",
    "                    })\n",
    "                    assigned += 1  \n",
    "            if assigned >= num_copies:\n",
    "                break\n",
    "        reservation_id_counter += 1\n",
    "# Convert lists to DataFrames\n",
    "df_reservation = pd.DataFrame(reservation_list)\n",
    "df_reservation_details = pd.DataFrame(reservation_details_list)\n",
    "\n",
    "# Update book_copy status based on reservations\n",
    "for copy_id in df_book_copy_updated['copy_id']:\n",
    "    queues = [r for r in reservation_details_list if r['copy_id'] == copy_id]\n",
    "    if not queues:\n",
    "        df_book_copy_updated.loc[df_book_copy_updated['copy_id'] == copy_id, 'status'] = 'Available'\n",
    "    else:\n",
    "        # Check the latest reservation returned_at\n",
    "        latest_res_id = max([r['reservation_id'] for r in queues])\n",
    "        returned_at = df_reservation.loc[df_reservation['reservation_id'] == latest_res_id, 'returned_at'].values[0]\n",
    "        df_book_copy_updated.loc[df_book_copy_updated['copy_id'] == copy_id, 'status'] = 'Checked Out' if pd.isna(returned_at) else 'Available'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef5f58",
   "metadata": {},
   "source": [
    "*Save as CSV*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c260b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "author.to_csv(\"data/author.csv\", index=False)\n",
    "book.to_csv(\"data/book.csv\", index=False)\n",
    "book_author.to_csv(\"data/book_author.csv\", index=False)\n",
    "book_category.to_csv(\"data/book_category.csv\", index=False)\n",
    "category.to_csv(\"data/category.csv\", index=False)\n",
    "description.to_csv(\"data/description.csv\", index=False)\n",
    "staff.to_csv(\"data/staff.csv\", index=False)\n",
    "member.to_csv(\"data/member.csv\", index=False)\n",
    "df_book_copy_updated.to_csv(\"data/book_copy.csv\", index=False)\n",
    "df_reservation.to_csv(\"data/reservation.csv\", index=False)\n",
    "df_reservation_details.to_csv(\"data/reservation_details.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
